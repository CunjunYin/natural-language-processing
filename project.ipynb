{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee82352e-5553-48e5-a623-611146796ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import gensim\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.corpora import Dictionary\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import seaborn as sns\n",
    "\n",
    "import multiprocessing as mp\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3746352-af85-4ef2-81c9-2e696aecf858",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not nltk.find('corpora/wordnet'):\n",
    "     nltk.download('wordnet')\n",
    "porter_stemmer  = PorterStemmer()\n",
    "lemmatizer      = WordNetLemmatizer()\n",
    "regex_tokenizer = nltk.tokenize.RegexpTokenizer(r\"\\w+\")\n",
    "spell  = SpellChecker()\n",
    "one_hot_vectorizer = CountVectorizer(binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43282ee-9d1a-443d-a4cc-c69b4a7e3393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bd08af5-d4b0-416b-a9c8-8e7306df0125",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "373dae4e-bd9c-4c88-bded-888e4eb1a698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    txt = ''\n",
    "    for word in text.split(\" \"):\n",
    "        # The EE is short hand on employee\n",
    "        if word=='ee' or word == 'EE':\n",
    "            txt += ' employee '\n",
    "        else:\n",
    "            txt = txt + ' ' + word.lower().strip() + ' '\n",
    "#     txt = ' '.join(word.lower() for word in text.split(\" \") word = 'employee' if word=='ee')\n",
    "    txt = txt.strip()\n",
    "    txt = re.sub(r\"([.,!?])\", r\" \\1 \", txt)\n",
    "    txt = re.sub(r\"[^a-zA-Z.,!?]+\", r\" \", txt)\n",
    "    return txt.strip()\n",
    "\n",
    "def tokenize(text):\n",
    "    return nltk.word_tokenize(text)\n",
    "\n",
    "def stem(words, df=False):\n",
    "    stemmed_words=[porter_stemmer.stem(word) for word in words]\n",
    "    if df:\n",
    "        return pd.DataFrame({'original': words,'stemmed': stemmed_words})\n",
    "    return stemmed_words\n",
    "\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return nltk.corpus.wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return nltk.corpus.wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return nltk.corpus.wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return nltk.corpus.wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def lemmatize(words, df=False):\n",
    "    lemmatized_words=[]\n",
    "    tagged_sent = nltk.pos_tag(words)\n",
    "    \n",
    "    for tag in tagged_sent:\n",
    "        wordnet_pos = get_wordnet_pos(tag[1]) or nltk.corpus.wordnet.NOUN\n",
    "        if wordnet_pos is None:\n",
    "            lemmatized_words.append(lemmatizer.lemmatize(tag[0]))\n",
    "        else:\n",
    "            lemmatized_words.append(lemmatizer.lemmatize(tag[0], pos=wordnet_pos))\n",
    "    \n",
    "    if df:\n",
    "        return pd.DataFrame({'original': words,'lemmatized': lemmatized_words})\n",
    "    return lemmatized_words\n",
    "\n",
    "def SK_TFIDF_stopwords(corpus, vectorizer):\n",
    "    vectorizer.fit(corpus)\n",
    "    X = vectorizer.transform(corpus)\n",
    "    return vectorizer.stop_words_, X\n",
    "\n",
    "def get_words(texts):\n",
    "    words = []\n",
    "    for text in texts:\n",
    "        words+=regex_tokenizer.tokenize(text)\n",
    "    return np.asarray(words).reshape(-1, 1)\n",
    "\n",
    "def OHE(sent):\n",
    "    enc = OneHotEncoder(handle_unknown='ignore')\n",
    "    words=[]\n",
    "    for w in sent.values:\n",
    "        words += w\n",
    "    X = enc.fit(np.array(words).reshape(-1,1))\n",
    "    return sent.apply(lambda x: enc.transform(np.array(x).reshape(-1,1))), X.n_features_in_\n",
    "    \n",
    "def spell_check(words):\n",
    "    return [spell.correction(word) for word in words]\n",
    "\n",
    "def remove_stopwords(words, stopwords):\n",
    "    return [w for w in words if w not in stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d4dde7-dae6-4523-b000-93ba6186655d",
   "metadata": {},
   "source": [
    "# Clean Narrative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7b9e2af-9940-49c7-92c3-515d1cb781cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MINE_ID</th>\n",
       "      <th>CONTROLLER_ID</th>\n",
       "      <th>CONTROLLER_NAME</th>\n",
       "      <th>OPERATOR_ID</th>\n",
       "      <th>OPERATOR_NAME</th>\n",
       "      <th>CONTRACTOR_ID</th>\n",
       "      <th>DOCUMENT_NO</th>\n",
       "      <th>SUBUNIT_CD</th>\n",
       "      <th>SUBUNIT</th>\n",
       "      <th>ACCIDENT_DT</th>\n",
       "      <th>CAL_YR</th>\n",
       "      <th>CAL_QTR</th>\n",
       "      <th>FISCAL_YR</th>\n",
       "      <th>FISCAL_QTR</th>\n",
       "      <th>ACCIDENT_TIME</th>\n",
       "      <th>DEGREE_INJURY_CD</th>\n",
       "      <th>DEGREE_INJURY</th>\n",
       "      <th>FIPS_STATE_CD</th>\n",
       "      <th>UG_LOCATION_CD</th>\n",
       "      <th>UG_LOCATION</th>\n",
       "      <th>UG_MINING_METHOD_CD</th>\n",
       "      <th>UG_MINING_METHOD</th>\n",
       "      <th>MINING_EQUIP_CD</th>\n",
       "      <th>MINING_EQUIP</th>\n",
       "      <th>EQUIP_MFR_CD</th>\n",
       "      <th>EQUIP_MFR_NAME</th>\n",
       "      <th>EQUIP_MODEL_NO</th>\n",
       "      <th>SHIFT_BEGIN_TIME</th>\n",
       "      <th>CLASSIFICATION_CD</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>ACCIDENT_TYPE_CD</th>\n",
       "      <th>ACCIDENT_TYPE</th>\n",
       "      <th>NO_INJURIES</th>\n",
       "      <th>TOT_EXPER</th>\n",
       "      <th>MINE_EXPER</th>\n",
       "      <th>JOB_EXPER</th>\n",
       "      <th>OCCUPATION_CD</th>\n",
       "      <th>OCCUPATION</th>\n",
       "      <th>ACTIVITY_CD</th>\n",
       "      <th>ACTIVITY</th>\n",
       "      <th>INJURY_SOURCE_CD</th>\n",
       "      <th>INJURY_SOURCE</th>\n",
       "      <th>NATURE_INJURY_CD</th>\n",
       "      <th>NATURE_INJURY</th>\n",
       "      <th>INJ_BODY_PART_CD</th>\n",
       "      <th>INJ_BODY_PART</th>\n",
       "      <th>SCHEDULE_CHARGE</th>\n",
       "      <th>DAYS_RESTRICT</th>\n",
       "      <th>DAYS_LOST</th>\n",
       "      <th>TRANS_TERM</th>\n",
       "      <th>RETURN_TO_WORK_DT</th>\n",
       "      <th>IMMED_NOTIFY_CD</th>\n",
       "      <th>IMMED_NOTIFY</th>\n",
       "      <th>INVEST_BEGIN_DT</th>\n",
       "      <th>NARRATIVE</th>\n",
       "      <th>CLOSED_DOC_NO</th>\n",
       "      <th>COAL_METAL_IND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100003</td>\n",
       "      <td>41044</td>\n",
       "      <td>Lhoist Group</td>\n",
       "      <td>L13586</td>\n",
       "      <td>Lhoist North America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.201210e+11</td>\n",
       "      <td>3</td>\n",
       "      <td>STRIP, QUARY, OPEN PIT</td>\n",
       "      <td>14/03/2012</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "      <td>945</td>\n",
       "      <td>5</td>\n",
       "      <td>DAYS RESTRICTED ACTIVITY ONLY</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>NO VALUE FOUND</td>\n",
       "      <td>?</td>\n",
       "      <td>NO VALUE FOUND</td>\n",
       "      <td>24</td>\n",
       "      <td>Front-end loader, Tractor-shovel, Payloader, H...</td>\n",
       "      <td>119</td>\n",
       "      <td>Not on this list</td>\n",
       "      <td>22321</td>\n",
       "      <td>600.0</td>\n",
       "      <td>12</td>\n",
       "      <td>POWERED HAULAGE</td>\n",
       "      <td>21</td>\n",
       "      <td>CGHT I, U, B, MVNG &amp; STTN OBJS</td>\n",
       "      <td>1</td>\n",
       "      <td>4.35</td>\n",
       "      <td>4.35</td>\n",
       "      <td>0.67</td>\n",
       "      <td>374</td>\n",
       "      <td>Warehouseman, Bagger, Palletizer/Stacker, Stor...</td>\n",
       "      <td>28</td>\n",
       "      <td>HANDLING SUPPLIES/MATERIALS</td>\n",
       "      <td>76</td>\n",
       "      <td>SURFACE MINING MACHINES</td>\n",
       "      <td>160</td>\n",
       "      <td>CONTUSN,BRUISE,INTAC SKIN</td>\n",
       "      <td>700</td>\n",
       "      <td>MULTIPLE PARTS (MORE THAN ONE MAJOR)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>03/26/2012</td>\n",
       "      <td>?</td>\n",
       "      <td>NO VALUE FOUND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Employee was cleaning up at the Primary Crushe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MINE_ID CONTROLLER_ID CONTROLLER_NAME OPERATOR_ID          OPERATOR_NAME  \\\n",
       "0   100003         41044    Lhoist Group      L13586  Lhoist North America    \n",
       "\n",
       "  CONTRACTOR_ID   DOCUMENT_NO  SUBUNIT_CD                 SUBUNIT ACCIDENT_DT  \\\n",
       "0           NaN  2.201210e+11           3  STRIP, QUARY, OPEN PIT  14/03/2012   \n",
       "\n",
       "   CAL_YR  CAL_QTR  FISCAL_YR  FISCAL_QTR  ACCIDENT_TIME DEGREE_INJURY_CD  \\\n",
       "0    2012        1       2012           2            945                5   \n",
       "\n",
       "                   DEGREE_INJURY  FIPS_STATE_CD UG_LOCATION_CD  \\\n",
       "0  DAYS RESTRICTED ACTIVITY ONLY              1              ?   \n",
       "\n",
       "      UG_LOCATION UG_MINING_METHOD_CD UG_MINING_METHOD MINING_EQUIP_CD  \\\n",
       "0  NO VALUE FOUND                   ?   NO VALUE FOUND              24   \n",
       "\n",
       "                                        MINING_EQUIP EQUIP_MFR_CD  \\\n",
       "0  Front-end loader, Tractor-shovel, Payloader, H...          119   \n",
       "\n",
       "     EQUIP_MFR_NAME EQUIP_MODEL_NO  SHIFT_BEGIN_TIME CLASSIFICATION_CD  \\\n",
       "0  Not on this list          22321             600.0                12   \n",
       "\n",
       "    CLASSIFICATION ACCIDENT_TYPE_CD                   ACCIDENT_TYPE  \\\n",
       "0  POWERED HAULAGE               21  CGHT I, U, B, MVNG & STTN OBJS   \n",
       "\n",
       "   NO_INJURIES  TOT_EXPER  MINE_EXPER  JOB_EXPER OCCUPATION_CD  \\\n",
       "0            1       4.35        4.35       0.67           374   \n",
       "\n",
       "                                          OCCUPATION ACTIVITY_CD  \\\n",
       "0  Warehouseman, Bagger, Palletizer/Stacker, Stor...          28   \n",
       "\n",
       "                      ACTIVITY INJURY_SOURCE_CD            INJURY_SOURCE  \\\n",
       "0  HANDLING SUPPLIES/MATERIALS               76  SURFACE MINING MACHINES   \n",
       "\n",
       "  NATURE_INJURY_CD              NATURE_INJURY INJ_BODY_PART_CD  \\\n",
       "0              160  CONTUSN,BRUISE,INTAC SKIN              700   \n",
       "\n",
       "                          INJ_BODY_PART  SCHEDULE_CHARGE  DAYS_RESTRICT  \\\n",
       "0  MULTIPLE PARTS (MORE THAN ONE MAJOR)              0.0            8.0   \n",
       "\n",
       "   DAYS_LOST TRANS_TERM RETURN_TO_WORK_DT IMMED_NOTIFY_CD    IMMED_NOTIFY  \\\n",
       "0        0.0          N        03/26/2012              ?   NO VALUE FOUND   \n",
       "\n",
       "  INVEST_BEGIN_DT                                          NARRATIVE  \\\n",
       "0             NaN  Employee was cleaning up at the Primary Crushe...   \n",
       "\n",
       "   CLOSED_DOC_NO COAL_METAL_IND  \n",
       "0            NaN              M  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('us_data_2000.csv')\n",
    "pd.options.display.max_columns = None\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23033e28-2b8f-4b8f-90db-04c43345aa04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEGREE_INJURY</th>\n",
       "      <th>DEGREE_INJURY_CD</th>\n",
       "      <th>NATURE_INJURY</th>\n",
       "      <th>INJ_BODY_PART</th>\n",
       "      <th>ACTIVITY</th>\n",
       "      <th>INJURY_SOURCE</th>\n",
       "      <th>NARRATIVE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DAYS RESTRICTED ACTIVITY ONLY</td>\n",
       "      <td>5</td>\n",
       "      <td>CONTUSN,BRUISE,INTAC SKIN</td>\n",
       "      <td>MULTIPLE PARTS (MORE THAN ONE MAJOR)</td>\n",
       "      <td>HANDLING SUPPLIES/MATERIALS</td>\n",
       "      <td>SURFACE MINING MACHINES</td>\n",
       "      <td>Employee was cleaning up at the Primary Crushe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   DEGREE_INJURY DEGREE_INJURY_CD              NATURE_INJURY  \\\n",
       "0  DAYS RESTRICTED ACTIVITY ONLY                5  CONTUSN,BRUISE,INTAC SKIN   \n",
       "\n",
       "                          INJ_BODY_PART                     ACTIVITY  \\\n",
       "0  MULTIPLE PARTS (MORE THAN ONE MAJOR)  HANDLING SUPPLIES/MATERIALS   \n",
       "\n",
       "             INJURY_SOURCE                                          NARRATIVE  \n",
       "0  SURFACE MINING MACHINES  Employee was cleaning up at the Primary Crushe...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_columns = 20\n",
    "df = df[['DEGREE_INJURY', 'DEGREE_INJURY_CD','NATURE_INJURY', 'INJ_BODY_PART', 'ACTIVITY', 'INJURY_SOURCE', 'NARRATIVE']]\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa999f8c-7ac3-4509-9ba1-e48b37b2f51e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DEGREE_INJURY       False\n",
       "DEGREE_INJURY_CD    False\n",
       "NATURE_INJURY       False\n",
       "INJ_BODY_PART       False\n",
       "ACTIVITY            False\n",
       "INJURY_SOURCE       False\n",
       "NARRATIVE           False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a409ba55-0332-4b0c-b284-f53034bad9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origin data size:       2000\n",
      "NARRATIVE NaN count:    0\n",
      "NARRATIVE len>10 count: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Origin data size:      \", df.shape[0])\n",
    "print('NARRATIVE NaN count:   ', df[df['NARRATIVE'].isna()].shape[0])\n",
    "print('NARRATIVE len>10 count:', df[df['NARRATIVE'].str.len() < 10].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e344ae3a-1e8c-4ac7-a56a-5f327fb664f2",
   "metadata": {},
   "source": [
    "#### Remove Narrative are too short and NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1531e8db-f9c6-434c-afb2-754c279b0b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean data size: 1999\n"
     ]
    }
   ],
   "source": [
    "df = df[df['NARRATIVE'].notna()]\n",
    "df = df[df['NARRATIVE'].str.len() > 10]\n",
    "print(\"Clean data size:\", df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fc34fe-6333-4ef7-b23d-56376feafb19",
   "metadata": {},
   "source": [
    "### To Lower case - Narrative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72accc8a-fe28-4502-bcd1-ea266391ad6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'employee was cleaning up at the primary crusher with the dingo skid steer . the employee slipped and fell while operating the skid steer and the machine pinned him against the cement retaining wall .'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with mp.Pool(mp.cpu_count()) as pool:\n",
    "    df['NARRATIVE'] = pool.map(clean_text, df['NARRATIVE'])\n",
    "df['NARRATIVE'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7e81ab-b43f-4682-9ad6-a2e612bb7877",
   "metadata": {},
   "source": [
    "### lem and stem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e6ae0e-c8ae-475f-bbd0-8f2ff1253ce9",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Test lem and stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32b354e0-d4d8-4957-ac9a-f84d078a8ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stem      = stem(nltk.tokenize.word_tokenize((df['NARRATIVE'].values[0])), df=True)\n",
    "df_lemmatize = lemmatize(nltk.tokenize.word_tokenize((df['NARRATIVE'].values[0])), df=True)\n",
    "df_stem['lemmatized'] = df_lemmatize['lemmatized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae202934-1156-47ff-b8c6-0f6e04a3a9b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>employee</td>\n",
       "      <td>employe</td>\n",
       "      <td>employee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>was</td>\n",
       "      <td>wa</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>primary</td>\n",
       "      <td>primari</td>\n",
       "      <td>primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>employee</td>\n",
       "      <td>employe</td>\n",
       "      <td>employee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>operating</td>\n",
       "      <td>oper</td>\n",
       "      <td>operate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>machine</td>\n",
       "      <td>machin</td>\n",
       "      <td>machine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     original  stemmed lemmatized\n",
       "0    employee  employe   employee\n",
       "1         was       wa         be\n",
       "6     primary  primari    primary\n",
       "15   employee  employe   employee\n",
       "20  operating     oper    operate\n",
       "26    machine   machin    machine"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stem[df_stem['stemmed'] != df_stem['lemmatized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8028de-ca99-45a2-b3d2-b2dada480db8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b1d81d9-8c70-48ea-99ee-f075c27acc16",
   "metadata": {},
   "source": [
    "### Lemmatize and stemming words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87083540-ed69-431d-a91b-bbfea07bff8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['employee', 'was', 'cleaning', 'up', 'at', 'the', 'primary', 'crusher', 'with', 'the', 'dingo', 'skid', 'steer', '.', 'the', 'employee', 'slipped', 'and', 'fell', 'while', 'operating', 'the', 'skid', 'steer', 'and', 'the', 'machine', 'pinned', 'him', 'against', 'the', 'cement', 'retaining', 'wall', '.']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize words\n",
    "with mp.Pool(mp.cpu_count()) as pool:\n",
    "    df['NARRATIVE_token'] = pool.map(tokenize, df['NARRATIVE'])\n",
    "print(df['NARRATIVE_token'][0])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a9a883f6-905d-4f99-aca7-3ab2d7fb6573",
   "metadata": {},
   "source": [
    "Some words used in this text were misspelled, so in code blow we use `spellchecker` package to correct words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd3b5d74-bf40-4ecd-ad47-3258b15fb33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['employee', 'was', 'cleaning', 'up', 'at', 'the', 'primary', 'crusher', 'with', 'the', 'dingo', 'skid', 'steer', '.', 'the', 'employee', 'slipped', 'and', 'fell', 'while', 'operating', 'the', 'skid', 'steer', 'and', 'the', 'machine', 'pinned', 'him', 'against', 'the', 'cement', 'retaining', 'wall', '.']\n"
     ]
    }
   ],
   "source": [
    "# Correct words\n",
    "with mp.Pool(mp.cpu_count()) as pool:\n",
    "    df['NARRATIVE_token'] = pool.map(spell_check, df['NARRATIVE_token'])\n",
    "print(df['NARRATIVE_token'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bfad740-3707-4974-aac4-226cffaae4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['employee', 'be', 'clean', 'up', 'at', 'the', 'primary', 'crusher', 'with', 'the', 'dingo', 'skid', 'steer', '.', 'the', 'employee', 'slip', 'and', 'fell', 'while', 'operate', 'the', 'skid', 'steer', 'and', 'the', 'machine', 'pin', 'him', 'against', 'the', 'cement', 'retain', 'wall', '.']\n"
     ]
    }
   ],
   "source": [
    "# Lemmatizing\n",
    "with mp.Pool(mp.cpu_count()) as pool:\n",
    "    df['NARRATIVE_LEM'] = pool.map(lemmatize, df['NARRATIVE_token'])\n",
    "print(df['NARRATIVE_LEM'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3f5d8c2-77a5-4fb2-a1fb-64970bd06b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['employe', 'wa', 'clean', 'up', 'at', 'the', 'primari', 'crusher', 'with', 'the', 'dingo', 'skid', 'steer', '.', 'the', 'employe', 'slip', 'and', 'fell', 'while', 'oper', 'the', 'skid', 'steer', 'and', 'the', 'machin', 'pin', 'him', 'against', 'the', 'cement', 'retain', 'wall', '.']\n"
     ]
    }
   ],
   "source": [
    "# Stemming\n",
    "with mp.Pool(mp.cpu_count()) as pool:\n",
    "    df['NARRATIVE_STEM'] = pool.map(stem, df['NARRATIVE_token'])\n",
    "print(df['NARRATIVE_STEM'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76b9e0e9-2d06-46d1-bb00-f234bca5f16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['employee', 'be', 'clean', 'up', 'at', 'the', 'primary', 'crusher', 'with', 'the', 'dingo', 'skid', 'steer', '.', 'the', 'employee', 'slip', 'and', 'fell', 'while', 'operate', 'the', 'skid', 'steer', 'and', 'the', 'machine', 'pin', 'him', 'against', 'the', 'cement', 'retain', 'wall', '.']\n"
     ]
    }
   ],
   "source": [
    "# Lemmatizing then Stemming\n",
    "with mp.Pool(mp.cpu_count()) as pool:\n",
    "    df['NARRATIVE_LEM_STEM'] = pool.map(lemmatize, df['NARRATIVE_LEM'])\n",
    "print(df['NARRATIVE_LEM_STEM'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c82ddc-184e-4ae9-bbf7-d0656d73ce14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a263af8-78cf-464c-a1d8-7da557d0f946",
   "metadata": {},
   "source": [
    "# Create Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac475063-3d46-4aef-a6ee-c4895eba23b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=['abb', 'ac', 'abc', 'bo', 'it', 'dia'], max_df=0.15, min_df=1)\n",
    "stopwrods, X  = SK_TFIDF_stopwords(df.apply(lambda row: ' '.join(row['NARRATIVE_LEM_STEM']), axis=1), vectorizer)\n",
    "print(len(stopwrods))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbc3a9fa-7233-4d02-9795-db7151ed3520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ascending\n",
      "               term      rank\n",
      "2149        pinched  0.134361\n",
      "2119  perpendicular  0.142193\n",
      "927       elevation  0.142193\n",
      "217            baby  0.147287\n",
      "39      acupuncture  0.147287\n",
      "3231    unknowingly  0.148739\n",
      "141      applicator  0.155270\n",
      "2681        silicon  0.155270\n",
      "999        exercise  0.156959\n",
      "2084    participate  0.156959\n",
      "3125            tow  0.157430\n",
      "618          consul  0.157588\n",
      "1665      lightbulb  0.157588\n",
      "2398          relax  0.157588\n",
      "836             dog  0.157588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cun/anaconda3/envs/CITS4012/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "terms = vectorizer.get_feature_names()\n",
    "# sum tfidf frequency of each term through documents\n",
    "\n",
    "sums = X.sum(axis=0)\n",
    "\n",
    "# connecting term to its sums frequency\n",
    "data = []\n",
    "for col, term in enumerate(terms):\n",
    "    data.append( (term, sums[0,col] ))\n",
    "\n",
    "ranking = pd.DataFrame(data, columns=['term','rank'])\n",
    "print('Ascending')\n",
    "print(ranking.sort_values('rank', ascending=True)[0:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "261603f1-7bac-44b0-b679-6cb8056a8b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descending\n",
      "        term       rank\n",
      "1045    fall  51.306178\n",
      "1642    left  44.523253\n",
      "1285    hand  44.288816\n",
      "1066    fell  43.290685\n",
      "1090  finger  42.824256\n",
      "2728    slip  42.404891\n",
      "702      cut  42.365139\n",
      "2502    roof  41.552680\n",
      "2492    rock  41.543241\n",
      "334     bolt  39.891685\n",
      "3404    work  39.028079\n",
      "1976     off  38.413776\n",
      "1311    have  37.090783\n",
      "2859    step  35.647977\n",
      "3254      up  34.777416\n"
     ]
    }
   ],
   "source": [
    "print('Descending')\n",
    "print(ranking.sort_values('rank', ascending=False)[0:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bfd776aa-f62e-4231-bf13-46befd078c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[stopwrods.add(w) for w in ['abb', 'ac', 'abc', 'bo', 'it', 'dia']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cdc51783-3e1d-4037-b6d8-2e97e149a358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abc', 'back', 'when', 'to', 'dia', 'with', 'ac', 'cause', 'the', 'bo', 'while', 'on', 'his', 'in', 'it', 'from', 'right', 'and', 'be', 'employee', 'at', 'abb', 'of', 'he'}\n"
     ]
    }
   ],
   "source": [
    "print(stopwrods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "658399cb-d9d5-4026-9cc0-a8abbd69f314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['employee', 'be', 'clean', 'up', 'at', 'the', 'primary', 'crusher', 'with', 'the', 'dingo', 'skid', 'steer', '.', 'the', 'employee', 'slip', 'and', 'fell', 'while', 'operate', 'the', 'skid', 'steer', 'and', 'the', 'machine', 'pin', 'him', 'against', 'the', 'cement', 'retain', 'wall', '.']\n",
      "['clean', 'up', 'primary', 'crusher', 'dingo', 'skid', 'steer', '.', 'slip', 'fell', 'operate', 'skid', 'steer', 'machine', 'pin', 'him', 'against', 'cement', 'retain', 'wall', '.']\n"
     ]
    }
   ],
   "source": [
    "print(df['NARRATIVE_LEM_STEM'][0])\n",
    "df['text'] = df['NARRATIVE_LEM_STEM'].apply(lambda x: remove_stopwords(x, stopwrods))\n",
    "print(df['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee75a3bc-b17c-4cab-baa7-ca120fbe9da9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3cc13934-5ed9-49aa-ae8f-1784a91506a1",
   "metadata": {},
   "source": [
    "# Binary Document Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47e426c5-f7ac-42b4-81b9-1043a8b04d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[['DEGREE_INJURY_CD', 'DEGREE_INJURY', 'text']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a58987a1-242b-4099-8ca0-bbeec58e7d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEGREE_INJURY_CD \"?\" count:  11\n",
      "DEGREE_INJURY NaN count:    0\n"
     ]
    }
   ],
   "source": [
    "print('DEGREE_INJURY_CD \"?\" count: ', data[data['DEGREE_INJURY_CD'] == '?'].shape[0])\n",
    "print('DEGREE_INJURY NaN count:   ', data[data['DEGREE_INJURY'].isna()].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74fabab9-6b8e-4a62-b2fb-c1027b75e196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origin data size: 1999\n",
      "Removed '?' data size: 1988\n"
     ]
    }
   ],
   "source": [
    "print(\"Origin data size:\", data.shape[0])\n",
    "data = data[data['DEGREE_INJURY_CD'] != '?']\n",
    "data['DEGREE_INJURY_CD'] = pd.to_numeric(data['DEGREE_INJURY_CD'])\n",
    "print(\"Removed '?' data size:\", data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85599ea3-bd42-4b90-a2bf-3d05cfdd0f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEGREE_INJURY_CD</th>\n",
       "      <th>DEGREE_INJURY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ACCIDENT ONLY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FATALITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>PERM TOT OR PERM PRTL DISABLTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>DAYS AWAY FROM WORK ONLY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>DYS AWY FRM WRK &amp; RESTRCTD ACT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>DAYS RESTRICTED ACTIVITY ONLY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>NO DYS AWY FRM WRK,NO RSTR ACT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>OCCUPATNAL ILLNESS NOT DEG 1-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>INJURIES DUE TO NATURAL CAUSES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>INJURIES INVOLVNG NONEMPLOYEES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>ALL OTHER CASES (INCL 1ST AID)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    DEGREE_INJURY_CD                   DEGREE_INJURY\n",
       "0                  0                   ACCIDENT ONLY\n",
       "1                  1                        FATALITY\n",
       "2                  2  PERM TOT OR PERM PRTL DISABLTY\n",
       "3                  3        DAYS AWAY FROM WORK ONLY\n",
       "4                  4  DYS AWY FRM WRK & RESTRCTD ACT\n",
       "5                  5   DAYS RESTRICTED ACTIVITY ONLY\n",
       "6                  6  NO DYS AWY FRM WRK,NO RSTR ACT\n",
       "7                  7  OCCUPATNAL ILLNESS NOT DEG 1-6\n",
       "8                  8  INJURIES DUE TO NATURAL CAUSES\n",
       "9                  9  INJURIES INVOLVNG NONEMPLOYEES\n",
       "10                10  ALL OTHER CASES (INCL 1ST AID)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_degree_injury(dataframe):\n",
    "    CD = []\n",
    "    INJURY = []\n",
    "    for i in range(0, len(dataframe.DEGREE_INJURY_CD.unique())):\n",
    "        CD.append(i)\n",
    "        INJURY.append(dataframe[dataframe['DEGREE_INJURY_CD'] == i]['DEGREE_INJURY'].values[0])\n",
    "    return pd.DataFrame({'DEGREE_INJURY_CD': CD,'DEGREE_INJURY': INJURY})\n",
    "get_degree_injury(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7197d34-4ece-47a0-92c7-c70aa5a363b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DAYS AWAY FROM WORK ONLY          29.879276\n",
       "NO DYS AWY FRM WRK,NO RSTR ACT    27.766600\n",
       "DAYS RESTRICTED ACTIVITY ONLY     18.058350\n",
       "ACCIDENT ONLY                     11.016097\n",
       "DYS AWY FRM WRK & RESTRCTD ACT     7.293763\n",
       "OCCUPATNAL ILLNESS NOT DEG 1-6     2.867203\n",
       "ALL OTHER CASES (INCL 1ST AID)     1.006036\n",
       "PERM TOT OR PERM PRTL DISABLTY     0.905433\n",
       "FATALITY                           0.553320\n",
       "INJURIES DUE TO NATURAL CAUSES     0.503018\n",
       "INJURIES INVOLVNG NONEMPLOYEES     0.150905\n",
       "Name: DEGREE_INJURY, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*data['DEGREE_INJURY'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "622b541e-e0d1-47e1-9cb0-e9e5da6368ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "group1 = [\n",
    "    'DAYS AWAY FROM WORK ONLY',\n",
    "    'DAYS RESTRICTED ACTIVITY ONLY',\n",
    "    'DYS AWY FRM WRK & RESTRCTD ACT'\n",
    "]\n",
    "data['OHE_DEGREE'] = data['DEGREE_INJURY'].isin(group1)\n",
    "data[\"OHE_DEGREE\"] = data[\"OHE_DEGREE\"].astype(int)\n",
    "del data['DEGREE_INJURY']\n",
    "del data['DEGREE_INJURY_CD']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2881936d-29a7-43df-b30b-abc356762d03",
   "metadata": {},
   "source": [
    "### Test one hot encoding and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a7d9930-feba-436f-b097-ac2a0296643d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['OHE'], dim = OHE(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8e74a4cc-481e-4be0-af0d-1fa20d4f931b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 3435)\n"
     ]
    }
   ],
   "source": [
    "print(data['OHE'].values[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ba077c5c-b645-45f5-a5aa-80f1fd3e6bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "67e8e36b-55b6-4f57-a242-b8cb663ddd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedforwardNeuralNetModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FeedforwardNeuralNetModel, self).__init__()\n",
    "        # Linear function 1: 784 --> 100\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim) \n",
    "        # Non-linearity 1\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        # Linear function 2: 100 --> 100\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        # Non-linearity 2\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        # Linear function 3: 100 --> 100\n",
    "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        # Non-linearity 3\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        # Linear function 4 (readout): 100 --> 10\n",
    "        self.fc4 = nn.Linear(hidden_dim, output_dim)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Linear function 1\n",
    "        out = self.fc1(x)\n",
    "        # Non-linearity 1\n",
    "        out = self.relu1(out)\n",
    "\n",
    "        # Linear function 2\n",
    "        out = self.fc2(out)\n",
    "        # Non-linearity 2\n",
    "        out = self.relu2(out)\n",
    "\n",
    "        # Linear function 2\n",
    "        out = self.fc3(out)\n",
    "        # Non-linearity 2\n",
    "        out = self.relu3(out)\n",
    "\n",
    "        # Linear function 4 (readout)\n",
    "        out = self.fc4(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcc4430-ba44-4dee-af00-9c563d0d9b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = dim*dim\n",
    "hidden_dim = 100\n",
    "output_dim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05042547-53c0-429e-a199-a48ef92178a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1741c2b-3e4f-4bf6-901b-24781cc5119b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b816faf-bc7d-4188-ad02-5474180339ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203094a3-4dab-4167-a6d3-79883ff77930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "68d95938-2862-4251-b3f8-6978b754c872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpus = ['Time flies flies like an arrow.',\n",
    "          'Fruit flies like a banana.']\n",
    "one_hot_vectorizer = CountVectorizer(binary=True)\n",
    "one_hot = one_hot_vectorizer.fit_transform(corpus).toarray()\n",
    "sns.heatmap(one_hot, annot=True,cbar=False,yticklabels=['Sentence 2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6895fa03-aebd-46ce-8598-441b26786800",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2312012-271e-4833-98b7-e589811c15bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(task1_data, test_size=0.2, random_state=42, shuffle=True, stratify=task1_data['OHE_DEGREE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cf23a4e-1531-40a8-a6d6-f0cdb6418f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 161520 \n",
      "Test size:  40380\n"
     ]
    }
   ],
   "source": [
    "print(\"Train size:\", train.shape[0], \"\\nTest size: \", test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb529c8e-232a-45db-aeea-8d133f64f8eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c81dd94f-25a3-41ee-b358-0c18ad12bda8",
   "metadata": {},
   "source": [
    "# Multi-class Document Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8441f32-e7f0-4a99-bf70-eccc3d6995f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb41a4ff-ec2c-450f-b17e-8399ad028617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7b93c56-8335-45c4-baad-7a15167fe595",
   "metadata": {},
   "source": [
    "# NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b34cae-0b1d-47df-b869-a8cc425a826b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5897a0-e467-41f9-ac90-32b633cdd6cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4ebee4a-b42f-45f8-8597-4564290a0255",
   "metadata": {},
   "source": [
    "# Bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b9105157-14d8-42f7-8722-612cab5abbf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         employee was cleaning up at the primary crushe...\n",
       "1         handle of sledgehammer broke and head of hamme...\n",
       "2         employee was climbing down a ladder and when h...\n",
       "3         he pulled a back muscle while stacking bags of...\n",
       "4         ee hands began to break out in a rash after he...\n",
       "                                ...                        \n",
       "202809    ee had been working with a heavy shovel in the...\n",
       "202810     hydraulic sleeve exploit causing a small explosn\n",
       "202811    the accident occurred on the conveyor belt tha...\n",
       "202812      uncovering valve pinched finger on right han . \n",
       "202813    while inspecting the skid loader after operati...\n",
       "Name: NARRATIVE, Length: 201900, dtype: object"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5f6d0eb7-94e0-4c23-9560-a2b71feff7d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['shoulder strain , neck pain .', 'slipped on truck step .',\n",
       "       'improper lifting techniques .', 'lifting forms for concrete',\n",
       "       'fault in top .', 'pulling feeder cable',\n",
       "       'pulling on belt slipped fell', 'roof fall in inactive slope .',\n",
       "       'cumulative trauma', 'carpal tunnel', 'heat exhaustion'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = (df['NARRATIVE'].str.len() < 30)\n",
    "df.loc[mask]['NARRATIVE'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4749c56c-8001-4982-8171-06f731be0fd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
